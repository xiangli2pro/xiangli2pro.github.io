<!DOCTYPE html>
<html lang="en" data-theme=""><head>
    <title> Xiang Li | Tensorflow2 learning note (1) </title>

    
    <meta charset="utf-8"><meta name="generator" content="Hugo 0.81.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
    <meta name="description" content="A lifetime learner. A part of nature.">
    
    <link rel="stylesheet"
          href="https://xiangli2pro.github.io/css/style.min.0c643de4008adca329f7a2d616ce308cca99d4ef45e4cca307323e7857910194.css"
          integrity="sha256-DGQ95ACK3KMp96LWFs4wjMqZ1O9F5MyjBzI&#43;eFeRAZQ="
          crossorigin="anonymous"
          type="text/css">
    
    <link rel="stylesheet"
        href="https://xiangli2pro.github.io/css/markupHighlight.min.f798cbda9aaa38f89eb38be6414bd082cfd71a6780375cbf67b6d2fb2b96491e.css"
        integrity="sha256-95jL2pqqOPies4vmQUvQgs/XGmeAN1y/Z7bS&#43;yuWSR4="
        crossorigin="anonymous"
        type="text/css">
    
        
        
        <link rel="stylesheet"
        href="https://xiangli2pro.github.io/css/customer.min.93e48a477ee532b5600ae5e4aff60bfc28ca5236f93908831b3c74f7423080e1.css"
        integrity="sha256-k&#43;SKR37lMrVgCuXkr/YL/CjKUjb5OQiDGzx090IwgOE="
        crossorigin="anonymous"
        media="screen" />
    
    <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"
    integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA=="
    crossorigin="anonymous" />

    
    
      
      
      
      <link rel="preconnect" href="https://fonts.googleapis.com" />
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
      <link href="https://fonts.googleapis.com/css2?family=Titillium&#43;Web&amp;display=swap" rel="stylesheet" />
    <link rel="shortcut icon" href="https://xiangli2pro.github.io/favicons/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="https://xiangli2pro.github.io/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://xiangli2pro.github.io/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://xiangli2pro.github.io/favicons/favicon-16x16.png">

    <link rel="canonical" href="https://xiangli2pro.github.io/tech/2021_0423_tf-part1/">

    
    
    
    
    <script type="text/javascript"
            src="https://xiangli2pro.github.io/js/anatole-header.min.0c05c0a90d28c968a1cad4fb31abd0b8e1264e788ccefed022ae1d3b6f627514.js"
            integrity="sha256-DAXAqQ0oyWihytT7MavQuOEmTniMzv7QIq4dO29idRQ="
            crossorigin="anonymous"></script>


    
    <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://xiangli2pro.github.io/images/dandan.jpeg"/>

<meta name="twitter:title" content="Tensorflow2 learning note (1)"/>
<meta name="twitter:description" content="Recently I have been taking a series of online courses to learn Tensorflow2, simply out of curiosity to know how it works, especially nowadays when almost everyone is talking about AI, deep learning, etc."/>


    

</head>
<body><div class="sidebar animated fadeInDown ">
    <div class="logo-title">
        <div class="title">
            <img src="https://xiangli2pro.github.io/images/dandan.jpeg" alt="profile picture">
            <h3 title=""><a href="/">Xiang Li</a></h3>
            <div class="description">
                <p>A lifetime learner. A part of nature.</p>
            </div>
        </div>
    </div>
    <ul class="social-links">
        
            <li>
                <a href="https://www.linkedin.com/in/xiang-li-505757129/" rel="me" aria-label="Linkedin">
                    <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="https://github.com/xiangli2pro" rel="me" aria-label="GitHub">
                    <i class="fab fa-github fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
    </ul>
    <div class="footer">
        <div class="by_farbox">&copy; Xiang Li  2021-2022 </div>
    </div>
</div>
<div class="main">
    <div class="page-top  animated fadeInDown ">
    <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
    </a>
    <ul class="nav" id="navMenu">
        
        
            
            <li><a 
                   href="/about/"
                        
                   title="">About</a></li>
        
            
            <li><a 
                   href="/tech/"
                        
                   title="">Tech</a></li>
        
            
            <li><a 
                   href="/life/"
                        
                   title="">Life</a></li>
        
            
            <li><a 
                   href="/resource/"
                        
                   title="">Resource</a></li>
        
        
        
    </ul>
</div>

    <div class="autopagerize_page_element">
        <div class="content">
    <div class="post  animated fadeInDown ">
        <div class="post-content">
            
            <div class="post-title">
                <h3>Tensorflow2 learning note (1)</h3>
                
                    <div class="info">
                        <em class="fas fa-calendar-day"></em>
                        <span class="date"> Fri, Apr 23, 2021
                                           </span>
                        <em class="fas fa-stopwatch"></em>
                        <span class="reading-time">9-minute read</span>
                        
                        <span class="separator"><a class="tag" href="/tags/python/">python</a><a class="tag" href="/tags/tensorflow2/">Tensorflow2</a></span>

                    </div>
                
            </div>

            <p>Â </p>
<p>Recently I have been taking a series of <a href="https://www.coursera.org/specializations/tensorflow2-deeplearning">online courses</a> to learn Tensorflow2, simply out of curiosity to know how it works, especially nowadays when almost everyone is talking about AI, deep learning, etc. ðŸ˜›. In the post, I will show how to build up a neural network model from scratch to classify images of human-written digits of 0 to 9. This is the part 1 of the Tensorflow2 mini-series, and it serves more like a template demonstrating the modeling pipeline than a sophisticated performance-oriented project. I just randomly set up the model architecture, and the accuracy of the test dataset using the trained neural network model is 97.91%. Some <a href="https://www.kaggle.com/elcaiseri/mnist-simple-cnn-keras-accuracy-0-99-top-1">models on Kaggle</a> can achieve test accuracy more than 99.00%, those are also good resources to learn how to process the image data and improve the model performance.</p>
<p>Personally, on one hand I feel amazed that deep learning models can achieve such impressive performance superior than the other traditional statistical or machine learning models such as support vector machine (SVM) or random forest (RF). However, on the other hand I can sense that the real challenge resides on (1) how to adjust the model structure or refine the data processing to increase the accuracy by 1%, 0.1% or just 0.01%? (2) understand what pattern/relationship the model has learned from the data? As for the first challenge, it seems to me that it would require professional experience and extensive experiments, those classical models available on <a href="https://keras.io/api/applications/">Keras Applications</a> do not look very intuitive. The second challenge is related to an emerging research area called <em>interpretable machine learning</em><cite><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></cite> <cite><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></cite>, and I have heard from a machine learning engineer working in a pharmaceutical company that they use graph neural networks (GNN) to understand the connections between the molecule structure of drugs and their properties. Those are definitely very interesting topics, I will explore more on them and hopefully I will be able to cover the topics in my blog in the future ðŸ¤”.</p>
<p>The simple modeling pipeline presented in the post mainly consists of four parts,</p>
<ul>
<li>Load modules and data</li>
<li>Construct model and specify training algorithm &amp; evaluation metrics</li>
<li>Train model using train set and set up stopping criteria</li>
<li>Evaluate model performance on test set</li>
</ul>
<p>and details are displayed below. The work is originally created on Google Colab with GPU processor.</p>
<p>Â </p>
<h4 id="1-load-modules-and-tensorflow2">1. Load modules and Tensorflow2</h4>
<p>Instead of installing Tensorflow2 on local computer, it&rsquo;s more convenient to use <a href="https://www.tensorflow.org/tutorials/quickstart/beginner">Google Colab</a>, which can import Tensorflow2 directly and specify faster GPU option.  Here the Colab default Tensorflow2 version is 2.x and I set the working directory to a folder in the Google Drive.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="kn">as</span> <span class="nn">tf</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Tensorflow2 version&#39;</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Conv2D</span><span class="p">,</span> <span class="n">MaxPooling2D</span><span class="p">,</span> 
                                     <span class="n">Softmax</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">BatchNormalization</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.preprocessing</span> <span class="kn">import</span> <span class="n">image</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">regularizers</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
</code></pre></div><pre><code>Tensorflow2 version 2.4.1
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># set working directory</span>

<span class="o">%</span> <span class="n">cd</span> <span class="o">/</span><span class="n">content</span><span class="o">/</span><span class="n">drive</span><span class="o">/</span><span class="n">MyDrive</span><span class="o">/</span><span class="n">Colab</span> <span class="n">Notebooks</span>
</code></pre></div><pre><code>/content/drive/MyDrive/Colab Notebooks
</code></pre>
<p>Â </p>
<h4 id="2-load-data">2. Load Data</h4>
<p>The MINST data can be loaded from Keras and is splitted into train set (60,000) and test set (10,000). I scale the image data to be in the range [0,1] and append a dummy third dimension, since the convolutional layer expects three dimensions. Some examples of the digit images and their corresponding labels are given below.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># load the MNIST Digits data</span>
<span class="n">mnist_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">mnist</span>
<span class="p">(</span><span class="n">train_images</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">),</span> <span class="p">(</span><span class="n">test_images</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist_data</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>

<span class="c1"># scale images to be in range [0,1]</span>
<span class="n">train_images_scale</span><span class="p">,</span> <span class="n">test_images_scale</span> <span class="o">=</span> <span class="n">train_images</span><span class="o">/</span><span class="mf">255.0</span><span class="p">,</span> <span class="n">test_images</span><span class="o">/</span><span class="mf">255.0</span>

<span class="c1"># add dummy channel dimension</span>
<span class="n">train_images_scale</span> <span class="o">=</span> <span class="n">train_images_scale</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">test_images_scale</span> <span class="o">=</span> <span class="n">test_images_scale</span><span class="p">[</span><span class="o">...</span><span class="p">,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&#34;train_images_scale shape:&#34;</span><span class="p">,</span> <span class="n">train_images_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&#34;test_images_scale shape:&#34;</span><span class="p">,</span> <span class="n">test_images_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</code></pre></div><pre><code>train_images_scale shape: (60000, 28, 28, 1)
test_images_scale shape: (10000, 28, 28, 1)
</code></pre>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># example images and labels</span>

<span class="n">random_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_images_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">idx</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">random_idx</span><span class="p">):</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">train_images_scale</span><span class="p">[</span><span class="n">idx</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greys&#39;</span><span class="p">)</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Digit {train_labels[idx]}&#39;</span><span class="p">)</span>
</code></pre></div><center><img src="/images/tf1-pic1.png"></center>
<p>Â </p>
<h4 id="3-build-and-compile-model">3. Build and Compile model</h4>
<p>I use model <em>Sequential</em> API to build up a neural network model of seven layers, and there is no specific rationals regarding the configuration, simply for fun ðŸ˜Ž. Note that the last <em>Dense</em> layer is set to have 10 units, since there are 10 digit classes. When compiling the model, specify <em>Adam</em> as the training algorithm, loss is calculated by <em>sparse_categorical_crossentropy</em>, and model performance is measured by <em>SparseCategoricalAccuracy</em>.  Then instantiate <em>my_model</em> from the defined model class and the summary is displayed below to show the layers structure and the number of parameters involved.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_model</span><span class="p">(</span><span class="n">input_shape</span><span class="p">):</span>

  <span class="c1"># specify layers</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
    <span class="n">Conv2D</span><span class="p">(</span><span class="n">filters</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">),</span> 
           <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;SAME&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> 
           <span class="n">input_shape</span><span class="o">=</span><span class="n">input_shape</span><span class="p">,</span> <span class="n">data_format</span><span class="o">=</span><span class="s1">&#39;channels_last&#39;</span><span class="p">,</span> 
           <span class="c1"># Conv2D expects (batch_size,dim,dim,channels); </span>
           <span class="c1"># specify the channel axis accordingly in data_format</span>
           <span class="n">name</span> <span class="o">=</span> <span class="s2">&#34;layer_1&#34;</span><span class="p">),</span>
    <span class="n">MaxPooling2D</span><span class="p">(</span><span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s2">&#34;layer_2&#34;</span><span class="p">),</span>
    <span class="n">Flatten</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&#34;layer_3&#34;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">),</span>
          <span class="n">name</span><span class="o">=</span><span class="s2">&#34;layer_4&#34;</span><span class="p">),</span> 
    <span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="s1">&#39;he_uniform&#39;</span><span class="p">,</span>
          <span class="n">bias_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">Constant</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
          <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">),</span>
          <span class="n">name</span><span class="o">=</span><span class="s2">&#34;layer_5&#34;</span><span class="p">),</span> 
    <span class="n">BatchNormalization</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s2">&#34;layer_6&#34;</span><span class="p">),</span>
    <span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="s1">&#39;softmax&#39;</span><span class="p">,</span> 
          <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">initializers</span><span class="o">.</span><span class="n">RandomNormal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.05</span><span class="p">),</span>
          <span class="n">bias_initializer</span><span class="o">=</span><span class="s2">&#34;zeros&#34;</span><span class="p">,</span>
          <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">regularizers</span><span class="o">.</span><span class="n">l2</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">),</span>
          <span class="n">name</span><span class="o">=</span><span class="s2">&#34;layer_7&#34;</span><span class="p">)</span>
    <span class="p">])</span>
  
  <span class="c1"># compile model</span>
  <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.001</span><span class="p">),</span> 
                <span class="n">loss</span><span class="o">=</span><span class="s1">&#39;sparse_categorical_crossentropy&#39;</span><span class="p">,</span>
                <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">SparseCategoricalAccuracy</span><span class="p">()])</span>
  
  <span class="k">return</span> <span class="n">model</span>

<span class="c1"># instantiate model</span>
<span class="n">my_model</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">train_images_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># display the model summary</span>
<span class="n">my_model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div><pre><code>Model: &quot;sequential&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
layer_1 (Conv2D)             (None, 14, 14, 16)        160       
_________________________________________________________________
layer_2 (MaxPooling2D)       (None, 4, 4, 16)          0         
_________________________________________________________________
layer_3 (Flatten)            (None, 256)               0         
_________________________________________________________________
layer_4 (Dense)              (None, 128)               32896     
_________________________________________________________________
layer_5 (Dense)              (None, 64)                8256      
_________________________________________________________________
layer_6 (BatchNormalization) (None, 64)                256       
_________________________________________________________________
layer_7 (Dense)              (None, 10)                650       
=================================================================
Total params: 42,218
Trainable params: 42,090
Non-trainable params: 128
_________________________________________________________________
</code></pre>
<p>Â </p>
<p>Before training the model, we first check the model performance using the initial weights. The test accuracy is 7.82%.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">get_test_evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>

  <span class="n">test_loss</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="k">print</span><span class="p">(</span><span class="s2">&#34;Test loss: {:.3f}</span><span class="se">\n</span><span class="s2">Test accuracy: {:.2f}%&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">test_loss</span><span class="p">,</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">test_acc</span><span class="p">))</span>

<span class="n">get_test_evaluate</span><span class="p">(</span><span class="n">my_model</span><span class="p">,</span> <span class="n">test_images_scale</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div><pre><code>Test loss: 2.335
Test accuracy: 7.82%
</code></pre>
<p>Â </p>
<h4 id="4-train-model">4. Train model</h4>
<p><em>mode.fit()</em> method is used to train the neural network model for 50 epochs and 15% of the training set is set aside as validation set. Note that there are many helpful callback classes we can make use of to manipulate the training process. For examples, we set <em>callbacks_early_stop</em> to tell the machine to stop updating if the validation loss is not improved for 3 consecutive epochs; <em>checkpoints_best</em> tells the machine to save the best model weights in terms of the validation loss; <em>checkpoints_epoch</em> makes the machine save the model weights after each epoch. The results from the first 5 epochs are given below.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># stop if val_loss stops improving for 3 consecutive epochs</span>
<span class="n">callbacks_early_stop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># reduce learning rate by a factor 0.5 if val_loss stops improving for 3 consecutive epochs</span>
<span class="n">callbacks_reduce_lr</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">factor</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># save the loss and metrics after each epoch in the .csv file</span>
<span class="n">callbacks_csv</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">CSVLogger</span><span class="p">(</span><span class="s2">&#34;train_results.csv&#34;</span><span class="p">)</span>

<span class="c1"># save the model weights after each epoch</span>
<span class="n">checkpoints_epoch</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;checkpoints_epoch/checkpoints_{epoch:03d}&#39;</span><span class="p">,</span>
                                                       <span class="n">frequency</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># save the best model weights in terms of the lowest val_loss</span>
<span class="n">checkpoints_best</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="s1">&#39;checkpoints_best/checkpoints_best&#39;</span><span class="p">,</span>
                                                       <span class="n">frequency</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">save_weights_only</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                                                      <span class="n">save_best_only</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">)</span>

<span class="c1"># train 50 epochs, and split 15% data as validation set</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">my_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train_images_scale</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> 
                       <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                       <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">callbacks_early_stop</span><span class="p">,</span> <span class="n">callbacks_reduce_lr</span><span class="p">,</span> <span class="n">callbacks_csv</span><span class="p">,</span>
                                  <span class="n">checkpoints_epoch</span><span class="p">,</span> <span class="n">checkpoints_best</span><span class="p">])</span>
</code></pre></div><div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># check the training metrics, which is also saved in the train_results.csv</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</code></pre></div><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }
<pre><code>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
</code></pre>
<p></style></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>loss</th>
      <th>sparse_categorical_accuracy</th>
      <th>val_loss</th>
      <th>val_sparse_categorical_accuracy</th>
      <th>lr</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.438134</td>
      <td>0.899392</td>
      <td>0.225271</td>
      <td>0.953444</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.130286</td>
      <td>0.968392</td>
      <td>0.164475</td>
      <td>0.953111</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.101795</td>
      <td>0.977137</td>
      <td>0.119016</td>
      <td>0.971222</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.086796</td>
      <td>0.980922</td>
      <td>0.118879</td>
      <td>0.971667</td>
      <td>0.001</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.077237</td>
      <td>0.983980</td>
      <td>0.119780</td>
      <td>0.972778</td>
      <td>0.001</td>
    </tr>
  </tbody>
</table>
</div>
<p>Â </p>
<h4 id="5-evaluate-model-performance">5. Evaluate model performance</h4>
<p>We now visualize how the model performance changes as the number of training epochs increases.  As shown from the plot, the loss and accuracy of both training and validation sets are decreasing and increasing, respectively. However, the loss and accuracy of validation set are worse than those of training set, which implies there is the overfitting issue. One may consider conducting data augmentation to increase the training size or adding regularizations to the weights.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">121</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;sparse_categorical_accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_sparse_categorical_accuracy&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;sparse_categorical_accuracy VS. epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;sparse_categorical_accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="c1"># plt.xticks(np.arange(epochs))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">122</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;loss VS. epochs&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="c1"># plt.xticks(np.arange(epochs))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Training&#39;</span><span class="p">,</span> <span class="s1">&#39;Validation&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;After model fitting:&#39;</span><span class="p">)</span>
<span class="n">get_test_evaluate</span><span class="p">(</span><span class="n">my_model</span><span class="p">,</span> <span class="n">test_images_scale</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div><center><img src="/images/tf1-pic2.png"></center>
<pre><code>After model fitting:
Test loss: 0.096
Test accuracy: 97.70%
</code></pre>
<p>Â </p>
<p>In addition, we evaluate the trained model on the test set and obtain the test accuracy 97.70%, which has dramatically increased from 7.82%, the value before model training. Moreover, we randomly select two test images and use the trained model to make predictions as well as the corresponding bar plot. It looks like the test images are clear and the model gives pretty good predictions ðŸ¥³.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># select two test images</span>
<span class="n">random_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">test_images_scale</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">random_images</span> <span class="o">=</span> <span class="n">test_images_scale</span><span class="p">[</span><span class="n">random_idx</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
<span class="n">random_labels</span> <span class="o">=</span> <span class="n">test_labels</span><span class="p">[</span><span class="n">random_idx</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>

<span class="c1"># make predictions</span>
<span class="n">random_predictions</span> <span class="o">=</span> <span class="n">my_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">random_images</span><span class="p">)</span>

<span class="c1"># plot</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span> <span class="n">wspace</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">random_predictions</span><span class="p">,</span> <span class="n">random_images</span><span class="p">,</span> <span class="n">random_labels</span><span class="p">)):</span>

  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">image</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greys&#39;</span><span class="p">)</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_xaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_yaxis</span><span class="p">()</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="bp">False</span><span class="p">)</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Digit {label}&#39;</span><span class="p">)</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)),</span> <span class="n">pred</span><span class="p">)</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)))</span>
  <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Model Prediction: {np.argmax(pred)}&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div><center><img src="/images/tf1-pic3.png"></center>
<p>Â </p>
<h4 id="6-load-model-weights-and-architecture">6. Load model weights and architecture</h4>
<p>As mentioned in section 4, we have set up some callbacks to save the model weights after each epoch and the best model weights of all epochs. Here we check the performances of model using weights from the last epoch and the best weights, respectively. It shows that test accuracy of model using the best weight is higher, with value 97.91%.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># build up models with same layers structure</span>
<span class="n">new_model_last</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">train_images_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">new_model_best</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">(</span><span class="n">train_images_scale</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># load the weights from the last epoch</span>
<span class="n">new_model_last</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s1">&#39;checkpoints_epoch&#39;</span><span class="p">))</span>

<span class="c1"># load the best weights</span>
<span class="n">new_model_best</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s1">&#39;checkpoints_best/checkpoints_best&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;Use weights from last epoch:&#39;</span><span class="p">)</span>
<span class="n">get_test_evaluate</span><span class="p">(</span><span class="n">new_model_last</span><span class="p">,</span> <span class="n">test_images_scale</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Use weights from best epoch:&#39;</span><span class="p">)</span>
<span class="n">get_test_evaluate</span><span class="p">(</span><span class="n">new_model_best</span><span class="p">,</span> <span class="n">test_images_scale</span><span class="p">,</span> <span class="n">test_labels</span><span class="p">)</span>
</code></pre></div><pre><code>Use weights from last epoch:
Test loss: 0.096
Test accuracy: 97.70%

Use weights from best epoch:
Test loss: 0.087
Test accuracy: 97.91%
</code></pre>
<p>Â </p>
<p>The <em>model.load_weights()</em> method is very useful in the scenario where one needs to stop then resume the training process. Method <em>model.load_model()</em> can be called if one wants to load a pre-trained model including both model architecture and weights. Furthermore, If one wants to extract the model configuration, method <em>model.get_config()</em> will retrieve the config in dictionary format, and it&rsquo;s also possible to obtain the config in <a href="https://www.tensorflow.org/guide/keras/save_and_serialize#architecture-only_saving">JSON or YAML format</a>.</p>
<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python">
<span class="c1"># extract model architecture</span>
<span class="n">config_dict</span> <span class="o">=</span> <span class="n">my_model</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>

<span class="c1"># load model architecture</span>
<span class="n">new_model_config</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="o">.</span><span class="n">from_config</span><span class="p">(</span><span class="n">config_dict</span><span class="p">)</span>
<span class="c1"># for models that are not sequential models, use tf.keras.Model.from_config()</span>
</code></pre></div><p>Â 
Â </p>
<section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p><a href="https://arxiv.org/abs/1901.04592">Interpretable machine learning: definitions, methods, and applications</a> <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://arxiv.org/abs/2010.09337">Interpretable Machine Learning &ndash; A Brief History, State-of-the-Art and Challenges</a> <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
</div>
        <div class="post-footer">
            <div class="info">
                
                
            </div>
        </div>

        <div id="fb_comments_container">
              
                <h2></h2>
                <script src="https://utteranc.es/client.js"
        repo="xiangli2pro/xiangli2pro.github.io"
        issue-term="pathname"
        theme="github-light"
        
        crossorigin="anonymous"
        async>
</script>

            </div>
    </div>


        </div>
    </div>
</div>

<script type="text/javascript"
        src="https://xiangli2pro.github.io/js/jquery.min.64d0083866906099f942140bc1c5cba4b1bf65783c52e4a63c5c46bf9dbc41f4.js"
        integrity="sha256-ZNAIOGaQYJn5QhQLwcXLpLG/ZXg8UuSmPFxGv528QfQ="
        crossorigin="anonymous"></script>




<script type="text/javascript"
        src="https://xiangli2pro.github.io/js/bundle.min.45159b0e20ba3878972e064b7edc464c31a9e35a0d0a6a71e3fec84efdbe2ea5.js"
        integrity="sha256-RRWbDiC6OHiXLgZLftxGTDGp41oNCmpx4/7ITv2&#43;LqU="
        crossorigin="anonymous"></script>

<script type="text/javascript"
        src="https://xiangli2pro.github.io/js/medium-zoom.min.2d6fd0be87fa98f0c9b4dc2536b312bbca48757f584f6ea1f394abc9bcc38fbc.js"
        integrity="sha256-LW/Qvof6mPDJtNwlNrMSu8pIdX9YT26h85SrybzDj7w="
        crossorigin="anonymous"></script><script defer
                type="text/javascript"
                src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
                integrity="sha384-e/4/LvThKH1gwzXhdbY2AsjR3rm7LHWyhIG5C0jiRfn8AN2eTN5ILeztWw0H9jmN"
                crossorigin="anonymous"></script>
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script></body>

</html>
