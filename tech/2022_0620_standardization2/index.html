<!DOCTYPE html>
<html lang="en" data-theme=""><head>
    <title> Xiang Li | Standardization in sparse penalized regressions (2) </title>

    
    <meta charset="utf-8"><meta name="generator" content="Hugo 0.81.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
    <meta name="description" content="A lifetime learner. A part of nature.">
    
    <link rel="stylesheet"
          href="https://xiangli2pro.github.io/css/style.min.0c643de4008adca329f7a2d616ce308cca99d4ef45e4cca307323e7857910194.css"
          integrity="sha256-DGQ95ACK3KMp96LWFs4wjMqZ1O9F5MyjBzI&#43;eFeRAZQ="
          crossorigin="anonymous"
          type="text/css">
    
    <link rel="stylesheet"
        href="https://xiangli2pro.github.io/css/markupHighlight.min.f798cbda9aaa38f89eb38be6414bd082cfd71a6780375cbf67b6d2fb2b96491e.css"
        integrity="sha256-95jL2pqqOPies4vmQUvQgs/XGmeAN1y/Z7bS&#43;yuWSR4="
        crossorigin="anonymous"
        type="text/css">
    
        
        
        <link rel="stylesheet"
        href="https://xiangli2pro.github.io/css/customer.min.93e48a477ee532b5600ae5e4aff60bfc28ca5236f93908831b3c74f7423080e1.css"
        integrity="sha256-k&#43;SKR37lMrVgCuXkr/YL/CjKUjb5OQiDGzx090IwgOE="
        crossorigin="anonymous"
        media="screen" />
    
    <link rel="stylesheet"
    href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"
    integrity="sha512-+4zCK9k+qNFUR5X+cKL9EIR+ZOhtIloNl9GIKS57V1MyNsYpYcUrUeQc9vNfzsWfV28IaLL3i96P9sdNyeRssA=="
    crossorigin="anonymous" />

    
    
      
      
      
      <link rel="preconnect" href="https://fonts.googleapis.com" />
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
      <link href="https://fonts.googleapis.com/css2?family=Titillium&#43;Web&amp;display=swap" rel="stylesheet" />
    <link rel="shortcut icon" href="https://xiangli2pro.github.io/favicons/favicon.ico" type="image/x-icon">
    <link rel="apple-touch-icon" sizes="180x180" href="https://xiangli2pro.github.io/favicons/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://xiangli2pro.github.io/favicons/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://xiangli2pro.github.io/favicons/favicon-16x16.png">

    <link rel="canonical" href="https://xiangli2pro.github.io/tech/2022_0620_standardization2/">

    
    
    
    
    <script type="text/javascript"
            src="https://xiangli2pro.github.io/js/anatole-header.min.0c05c0a90d28c968a1cad4fb31abd0b8e1264e788ccefed022ae1d3b6f627514.js"
            integrity="sha256-DAXAqQ0oyWihytT7MavQuOEmTniMzv7QIq4dO29idRQ="
            crossorigin="anonymous"></script>


    
    <meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="https://xiangli2pro.github.io/images/dandan.jpeg"/>

<meta name="twitter:title" content="Standardization in sparse penalized regressions (2)"/>
<meta name="twitter:description" content="In the first post of the series, we learnt that it&rsquo;s recommended to standardize the input data before performing sparse penalized regressions and four standardization methods (Z-score, Gelman, Bring, Min-max) have been introduced with example R code."/>


    

</head>
<body><div class="sidebar animated fadeInDown ">
    <div class="logo-title">
        <div class="title">
            <img src="https://xiangli2pro.github.io/images/dandan.jpeg" alt="profile picture">
            <h3 title=""><a href="/">Xiang Li</a></h3>
            <div class="description">
                <p>A lifetime learner. A part of nature.</p>
            </div>
        </div>
    </div>
    <ul class="social-links">
        
            <li>
                <a href="https://www.linkedin.com/in/xiang-li-505757129/" rel="me" aria-label="Linkedin">
                    <i class="fab fa-linkedin fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
            <li>
                <a href="https://github.com/xiangli2pro" rel="me" aria-label="GitHub">
                    <i class="fab fa-github fa-2x" aria-hidden="true"></i>
                </a>
            </li>
        
    </ul>
    <div class="footer">
        <div class="by_farbox">&copy; Xiang Li  2021-2023 </div>
    </div>
</div>
<div class="main">
    <div class="page-top  animated fadeInDown ">
    <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
    </a>
    <ul class="nav" id="navMenu">
        
        
            
            <li><a 
                   href="/about/"
                        
                   title="">About</a></li>
        
            
            <li><a 
                   href="/tech/"
                        
                   title="">Tech</a></li>
        
            
            <li><a 
                   href="/life/"
                        
                   title="">Life</a></li>
        
            
            <li><a 
                   href="/resource/"
                        
                   title="">Resource</a></li>
        
        
        
    </ul>
</div>

    <div class="autopagerize_page_element">
        <div class="content">
    <div class="post  animated fadeInDown ">
        <div class="post-content">
            
            <div class="post-title">
                <h3>Standardization in sparse penalized regressions (2)</h3>
                
                    <div class="info">
                        <em class="fas fa-calendar-day"></em>
                        <span class="date"> Mon, Jun 20, 2022
                                           </span>
                        <em class="fas fa-stopwatch"></em>
                        <span class="reading-time">5-minute read</span>
                        
                        <span class="separator"><a class="tag" href="/tags/standardization/">standardization</a><a class="tag" href="/tags/statistics/">statistics</a></span>

                    </div>
                
            </div>

            <p>Â </p>
<p>In the <a href="https://xiangli2pro.github.io/tech/2022_0522_standardization1/">first post</a> of the series, we learnt that it&rsquo;s recommended to standardize the input data before performing sparse penalized regressions and four standardization methods (Z-score, Gelman, Bring, Min-max) have been introduced with example R code. In this post, I will briefly present a new standardization  approach,  Mixed standardization, proposed in our paper<cite><sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></cite> that aims to fairly select variables of heterogenous types.</p>
<p>Naturally someone may ask why do we need a new standardization, given that there are already four methods available? Let&rsquo;s take a step back and consider a common scenario where data $X$ has both continuous and binary variables. We can further treat such a data as a combination of two sub-data, one $X_c$ with only continuous variables and the other $X_b$ with only binary variables. When applying sparse penalized regressions, two issues indicated by paper<cite><sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup></cite> are: 1) Lasso-type regressions naturally select features from the the block with the highest signal (e.g. <a href="https://statproofbook.github.io/D/snr.html">signal-to-noise ratio</a>) first, the resulting shrinkage noise  will mask the weaker signals from other blocks and compromise our ability to select from these weaker blocks, especially when sample size is not sufficiently large; 2) By Lasso&rsquo;s beta-min condition, continuous (e.g. Gaussian) variables are more likely to be selected than the binary variables since the former requires lower signal for selection. Therefore, the type of the variable will affect its chance of being selected in the sparse penalized regressions when variables of mixed types (i.e. continuous, binary, categorical, etc) coexist in the same data.</p>
<p>Does the aforementioned four standardization (Z-score, Gelman, Bring, Min-max) address the influence of variables being heterogenous in the sparse regressions? The answer is no. No matter which one of the four standardization is applied on the data, even if variables have the same mean (first moment) and standard deviation (second moment), they still differ in higher moments hence are essentially different types. With respect to this, we propose the Mixed standardization that aims to alleviate the discrepancy across variables of different types in sparse regressions. The idea is straightforward, if the data has both continuous and binary variables, we convert continuous variables to binary variables with a data-dependent threshold, then we standardize all variables with their standard deviations. An example of performing the Mixed standardization is given below.</p>
<p>Suppose a data has 10 variables in total, the first 8 are binary variables ($X_1,&hellip;,X_8$) of different empirical probabilities ($0&lt;p_1,&hellip;,p_8&lt;1$) and the rest two are continuous variables ($X_9,X_{10}$). It&rsquo;s a common scenario in survey data where more binary variables are collected than continuous variables. We standardize the data following the steps,</p>
<ol>
<li>Set a threshold $p$. By default $p=0.5$, or take a value where the majority of ($p_1,&hellip;,p_8$) is centered at.</li>
<li>Dichotomize continuous variables ($X_9,X_{10}$) to binary. If a value is less than $p$th percentile of the variable observations, then set it as 1, otherwise 0.</li>
<li>Standardize all variables (original binary  variables + new binary variables after dichotomization) by their standard deviations.</li>
</ol>
<p>The Mixed standardization is based on the assumption that all the observed variables in a data, no matter what types they are at observation, they are all generated from latent continuous variables via some unknown mechanisms. In addition, it has been proved that applying the Mixed standardization enables variables to have comparable probabilities of being selected in lasso-type sparse regressions, regardless of their types (i.e. continuous, binary, categorical). The simulation has shown that lasso with Z-score, Gelman and Bring standardization tend to select more continuous variables than binary variables. By contrast, lasso with Min-max tend to select more binary variables than continuous variables, while the new standardization makes all variables have similar probabilities of being selected. When comparing the five methods (Z-score, Gelman, Bring, Min-max, Mixed) on the National Ambulatory Medical Care Survey data to select factors related to the opioid prescription in US, lasso with the Mixed standardized data selects the least number of variables but has the highest AUC score.</p>
<p>One thing worth emphasizing is that the Mixed standardization is proposed for improving variable selection in sparse regressions, not for coefficient estimations or prediction performance. Though some sparse penalized regressions (adaptive lasso) have been theoretically proved to have oracle property, i.e. the selected variables and their estimated coefficients are consistent with the truth subject to some asymptotic and regularity conditions. <em>The oracle property do not automatically result in optimal prediction performance</em><cite><sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup></cite>. So we recommend in practice, first to select variables by applying the sparse penalized regression on standardized variables, then fit an unpenalized regression on the selected variables in their unstandardized format to estimate the coefficients and perform predictions.</p>
<p>Lastly, we apply lasso with the Mixed standardization on the same baseball player data as in the first post, to select variables associated with player&rsquo;s salary. The result shows that the method selects 6 continuous variables.</p>
<div class="highlight"><pre class="chroma"><code class="language-r" data-lang="r"><span class="c1"># load package</span>
<span class="n">devtools</span><span class="o">::</span><span class="nf">install_github</span><span class="p">(</span><span class="s">&#34;xiangli2pro/mixedStandardization&#34;</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">mixedStandardization</span><span class="p">)</span>

<span class="c1"># load data</span>
<span class="nf">library</span><span class="p">(</span><span class="n">ISLR2</span><span class="p">)</span>
<span class="nf">data</span><span class="p">(</span><span class="n">Hitters</span><span class="p">)</span>
<span class="n">Hitters</span> <span class="o">&lt;-</span> <span class="nf">na.omit</span><span class="p">(</span><span class="n">Hitters</span><span class="p">)</span>
<span class="nf">dim</span><span class="p">(</span><span class="n">Hitters</span><span class="p">)</span>
<span class="c1"># 263  20</span>

<span class="c1"># check the continuous, binary and categorical variables</span>
<span class="nf">sapply</span><span class="p">(</span><span class="n">Hitters</span><span class="p">,</span> <span class="nf">function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="nf">length</span><span class="p">(</span><span class="nf">levels</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
<span class="n">binaryVars</span> <span class="o">&lt;-</span> <span class="nf">c</span><span class="p">(</span><span class="s">&#34;League&#34;</span><span class="p">,</span> <span class="s">&#34;Division&#34;</span><span class="p">,</span> <span class="s">&#34;NewLeague&#34;</span><span class="p">)</span>
<span class="n">conitnuousVars</span> <span class="o">&lt;-</span> <span class="nf">names</span><span class="p">(</span><span class="n">Hitters</span><span class="p">)</span><span class="n">[</span><span class="o">!</span><span class="nf">names</span><span class="p">(</span><span class="n">Hitters</span><span class="p">)</span> <span class="o">%in%</span> <span class="nf">c</span><span class="p">(</span><span class="n">binaryVars</span><span class="p">,</span> <span class="s">&#34;Salary&#34;</span><span class="p">)</span><span class="n">]</span>

<span class="c1"># perform cross-validation lasso for data standardized by different methods</span>
<span class="c1"># use &#34;one standard deviation&#34; rule to select the tuning lambda </span>
<span class="nf">library</span><span class="p">(</span><span class="n">glmnet</span><span class="p">)</span>
<span class="n">grid</span> <span class="o">&lt;-</span> <span class="m">10</span><span class="nf">^seq</span><span class="p">(</span><span class="m">10</span><span class="p">,</span> <span class="m">-2</span><span class="p">,</span> <span class="n">length</span> <span class="o">=</span> <span class="m">100</span><span class="p">)</span>

<span class="c1"># standardize input</span>
<span class="n">x_Mixedstand</span> <span class="o">&lt;-</span> <span class="nf">mixedStand</span><span class="p">(</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">Hitters</span><span class="p">,</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">Hitters</span><span class="o">$</span><span class="n">Salary</span><span class="p">,</span>
  <span class="n">standardization</span> <span class="o">=</span> <span class="s">&#34;Mixed&#34;</span><span class="p">,</span>
  <span class="n">continuousVars</span> <span class="o">=</span> <span class="n">conitnuousVars</span><span class="p">,</span>
  <span class="n">binaryVars</span> <span class="o">=</span> <span class="n">binaryVars</span>
<span class="p">)</span>

<span class="c1"># cross-validation of lasso</span>
<span class="n">lasso_cv</span> <span class="o">&lt;-</span> <span class="nf">cv.glmnet</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="nf">as.matrix</span><span class="p">(</span><span class="n">x_Mixedstand</span><span class="p">),</span> <span class="n">y</span> <span class="o">=</span> <span class="n">Hitters</span><span class="o">$</span><span class="n">Salary</span><span class="p">,</span> 
                      <span class="n">alpha</span> <span class="o">=</span> <span class="m">1</span><span class="p">,</span> <span class="n">standardize</span> <span class="o">=</span> <span class="kc">FALSE</span><span class="p">,</span> <span class="n">family</span> <span class="o">=</span> <span class="s">&#34;gaussian&#34;</span><span class="p">)</span>
<span class="c1"># coefficient estimation of lambda.1se</span>
<span class="n">lasso1se_coef</span> <span class="o">&lt;-</span> <span class="n">lasso_cv</span><span class="o">$</span><span class="n">glmnet.fit</span><span class="o">$</span><span class="n">beta[</span><span class="p">,</span> <span class="nf">which</span><span class="p">(</span><span class="n">lasso_cv</span><span class="o">$</span><span class="n">lambda</span> <span class="o">==</span> <span class="n">lasso_cv</span><span class="o">$</span><span class="n">lambda.1se</span><span class="p">)</span><span class="n">]</span>
<span class="c1"># selected variables (nonzero coefficients)</span>
<span class="nf">which</span><span class="p">(</span><span class="n">lasso1se_coef</span> <span class="o">!=</span> <span class="m">0</span><span class="p">)</span>
<span class="c1"># Hits    RBI  Walks CAtBat  CRuns   CRBI</span>
</code></pre></div><section class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>Standardization of Continuous and Categorical Covariates in Sparse Penalized Regressions <a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p><a href="https://arxiv.org/pdf/1903.11232.pdf">Feature Selection for Data Integration with Mixed Multi-view Data</a> <a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3" role="doc-endnote">
<p><a href="https://www.tandfonline.com/doi/abs/10.1198/016214506000000735">The adaptive lasso and its oracle properties</a> <a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</section>
</div>
        <div class="post-footer">
            <div class="info">
                
                
            </div>
        </div>

        <div id="fb_comments_container">
                    
                    <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-xiangli2pro-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                </div>
    </div>


        </div>
    </div>
</div>

<script type="text/javascript"
        src="https://xiangli2pro.github.io/js/jquery.min.64d0083866906099f942140bc1c5cba4b1bf65783c52e4a63c5c46bf9dbc41f4.js"
        integrity="sha256-ZNAIOGaQYJn5QhQLwcXLpLG/ZXg8UuSmPFxGv528QfQ="
        crossorigin="anonymous"></script>




<script type="text/javascript"
        src="https://xiangli2pro.github.io/js/bundle.min.45159b0e20ba3878972e064b7edc464c31a9e35a0d0a6a71e3fec84efdbe2ea5.js"
        integrity="sha256-RRWbDiC6OHiXLgZLftxGTDGp41oNCmpx4/7ITv2&#43;LqU="
        crossorigin="anonymous"></script>

<script type="text/javascript"
        src="https://xiangli2pro.github.io/js/medium-zoom.min.2d6fd0be87fa98f0c9b4dc2536b312bbca48757f584f6ea1f394abc9bcc38fbc.js"
        integrity="sha256-LW/Qvof6mPDJtNwlNrMSu8pIdX9YT26h85SrybzDj7w="
        crossorigin="anonymous"></script><script defer
                type="text/javascript"
                src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
                integrity="sha384-e/4/LvThKH1gwzXhdbY2AsjR3rm7LHWyhIG5C0jiRfn8AN2eTN5ILeztWw0H9jmN"
                crossorigin="anonymous"></script>
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
        </script></body>

</html>
